{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNSIT(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1,128,3,1,1)\n",
    "        self.conv2 = nn.Conv2d(128,128,3,1,1)\n",
    "        self.linear1 = nn.Linear(1152,256)\n",
    "        self.linear2 = nn.Linear(256,10)\n",
    "        self.drop1 = nn.Dropout2d(p=0.3)\n",
    "        self.drop2 = nn.Dropout(p=0.75)\n",
    "        self.maxpool = nn.MaxPool2d(2,2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.drop1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.drop1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.drop1(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.drop2(x)\n",
    "        x = self.linear2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "conv1.bias\n",
      "conv2.weight\n",
      "conv2.bias\n",
      "linear1.weight\n",
      "linear1.bias\n",
      "linear2.weight\n",
      "linear2.bias\n"
     ]
    }
   ],
   "source": [
    "model = MNSIT().cuda()\n",
    "for param_names,param in model.named_parameters():\n",
    "    print(param_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 128, 28, 28]           1,280\n",
      "            Conv2d-2          [-1, 128, 28, 28]         147,584\n",
      "              ReLU-3          [-1, 128, 28, 28]               0\n",
      "         MaxPool2d-4          [-1, 128, 14, 14]               0\n",
      "         Dropout2d-5          [-1, 128, 14, 14]               0\n",
      "            Conv2d-6          [-1, 128, 14, 14]         147,584\n",
      "            Conv2d-7          [-1, 128, 14, 14]         147,584\n",
      "              ReLU-8          [-1, 128, 14, 14]               0\n",
      "         MaxPool2d-9            [-1, 128, 7, 7]               0\n",
      "        Dropout2d-10            [-1, 128, 7, 7]               0\n",
      "           Conv2d-11            [-1, 128, 7, 7]         147,584\n",
      "           Conv2d-12            [-1, 128, 7, 7]         147,584\n",
      "             ReLU-13            [-1, 128, 7, 7]               0\n",
      "        MaxPool2d-14            [-1, 128, 3, 3]               0\n",
      "        Dropout2d-15            [-1, 128, 3, 3]               0\n",
      "          Flatten-16                 [-1, 1152]               0\n",
      "           Linear-17                  [-1, 256]         295,168\n",
      "             ReLU-18                  [-1, 256]               0\n",
      "          Dropout-19                  [-1, 256]               0\n",
      "           Linear-20                   [-1, 10]           2,570\n",
      "================================================================\n",
      "Total params: 1,036,938\n",
      "Trainable params: 1,036,938\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 3.53\n",
      "Params size (MB): 3.96\n",
      "Estimated Total Size (MB): 7.48\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model=model,input_size=(1,28,28),device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(torchvision.datasets.MNIST('/files/', train=True, download=False,\n",
    "                                          transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                          torchvision.transforms.Normalize((0.1307,), (0.3081,)).cuda()])),batch_size=32, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(torchvision.datasets.MNIST('/files/', train=False, download=False,\n",
    "                                          transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                          torchvision.transforms.Normalize((0.1307,), (0.3081,)).cuda()])),batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAckElEQVR4nO3dfXBUdb7n8U/zkBY0aQwhDy0Bw4MwCsQrSialMjikSOIUxdOdBR/qguVggcES0NHNrIoyVsXBXcery8DdKgfGuoLKvQIl6+BiMKEcE1wiXC6lk0swSryQoEzRHYKEQH77B2vPtCToaTp8k877VXWqSPf55vw8trw9dOfgc845AQBwmfWxXgAAoHciQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwEQ/6wV8V3t7u44cOaLk5GT5fD7r5QAAPHLOqbm5WcFgUH36dH6d0+0CdOTIEWVnZ1svAwBwiRoaGjR06NBOn+92AUpOTpYk3aY71U/9jVcDAPDqrNr0gd6J/H7emS4L0OrVq/X888+rsbFRubm5evnllzVp0qTvnfv2j936qb/6+QgQAPQ4//8Oo9/3NkqXfAjhjTfe0PLly7VixQp9/PHHys3NVWFhoY4dO9YVhwMA9EBdEqAXXnhBCxcu1H333afrr79ea9eu1cCBA/X73/++Kw4HAOiB4h6gM2fOqKamRgUFBX89SJ8+KigoUFVV1QX7t7a2KhwOR20AgMQX9wB9/fXXOnfunDIyMqIez8jIUGNj4wX7l5WVKRAIRDY+AQcAvYP5D6KWlpYqFApFtoaGBuslAQAug7h/Ci4tLU19+/ZVU1NT1ONNTU3KzMy8YH+/3y+/3x/vZQAAurm4XwElJSVp4sSJKi8vjzzW3t6u8vJy5efnx/twAIAeqkt+Dmj58uWaP3++br75Zk2aNEkvvviiWlpadN9993XF4QAAPVCXBGju3Ln66quv9NRTT6mxsVE33nijtm/ffsEHEwAAvZfPOeesF/G3wuGwAoGApmgGd0IAgB7orGtThbYqFAopJSWl0/3MPwUHAOidCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABP9rBeA3sXn93ue+cu8mzzPhH920vOMJK2d+Jrnmfur5nueGfXSWc8z+ujfvc90c32HDPE80x4Oe55xra2eZ9D1uAICAJggQAAAE3EP0NNPPy2fzxe1jR07Nt6HAQD0cF3yHtANN9yg9957768H6cdbTQCAaF1Shn79+ikzM7MrvjUAIEF0yXtABw8eVDAY1IgRI3TPPffo8OHDne7b2tqqcDgctQEAEl/cA5SXl6f169dr+/btWrNmjerr63X77berubm5w/3LysoUCAQiW3Z2dryXBADohuIeoOLiYv385z/XhAkTVFhYqHfeeUcnTpzQm2++2eH+paWlCoVCka2hoSHeSwIAdENd/umAQYMG6brrrlNdXV2Hz/v9fvlj+OFEAEDP1uU/B3Ty5EkdOnRIWVlZXX0oAEAPEvcAPfroo6qsrNTnn3+uDz/8ULNmzVLfvn111113xftQAIAeLO5/BPfll1/qrrvu0vHjxzVkyBDddtttqq6u1pAY7vkEAEhcPuecs17E3wqHwwoEApqiGern62+9HFxE3+uv8zxz7R86/0h+Z14Ofuh55uY9d3uekaTA2mTPM74Y/gsaeOCI55kv/3649wNdRjfN836z1LyUzzzP7D05zPPMv/+PXM8zkpT8RnVMc73dWdemCm1VKBRSSkpKp/txLzgAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwESX/4V0SFxJa0KeZ5aml3ueuXPOYs8zwYavPc9I0ufzUz3P/Kj4PzzPrL12q+eZq/sM8DyTiPoO+k/PM60v7IrpWH83+mHPM9nPer95bm/FFRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDdsqO/oETHNrRy+wfPMP/y3RzzPBKqrPc8c3JjreUaSPp38P2Oa8877na3v+bzA88wX4as9z0hS02dpnmeC78d0qMviL/NaYprbu/gfPc9MPOv9DtrXPNc776DNFRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIKbkUINszJjmltW9188zwQ2/F/PM76JN3ie2Zy/1vOMJE2o/oXnmexnvR+n71cnPM+ca/rK80xK2188z0hSig7FNNddJW+7Iqa52/7lHs8zU+bUeJ45+JznkYTAFRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIKbkSaYvqNHeJ7Z9dB/j+lYk//xUc8zwfbDnmfOXO39RpL/ULbc84wkDf2nKs8zLobjnI1hBrFrP306prnw3sHeh4q+iOlYvRFXQAAAEwQIAGDCc4B27dql6dOnKxgMyufzacuWLVHPO+f01FNPKSsrSwMGDFBBQYEOHjwYr/UCABKE5wC1tLQoNzdXq1ev7vD5VatW6aWXXtLatWu1e/duXXnllSosLNTpGP8MFgCQmDx/CKG4uFjFxcUdPuec04svvqgnnnhCM2bMkCS9+uqrysjI0JYtWzRv3rxLWy0AIGHE9T2g+vp6NTY2qqCgIPJYIBBQXl6eqqo6/nRRa2urwuFw1AYASHxxDVBjY6MkKSMjI+rxjIyMyHPfVVZWpkAgENmys7PjuSQAQDdl/im40tJShUKhyNbQ0GC9JADAZRDXAGVmZkqSmpqaoh5vamqKPPddfr9fKSkpURsAIPHFNUA5OTnKzMxUeXl55LFwOKzdu3crPz8/nocCAPRwnj8Fd/LkSdXV1UW+rq+v1759+5Samqphw4Zp6dKlevbZZzV69Gjl5OToySefVDAY1MyZM+O5bgBAD+c5QHv27NEdd9wR+Xr58vP33Jo/f77Wr1+vxx57TC0tLXrggQd04sQJ3Xbbbdq+fbuuuML7/bwAAInLc4CmTJki5zq//aLP59PKlSu1cuXKS1oYYvOfP+v4vbaL2fFNVkzHGrrm3zzPtMdwnP7v1XieSXsvhgMBuKzMPwUHAOidCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYMLz3bCReE61+2Oaa29pifNKAPQmXAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACa4GWmCuWbG555nVr47O6ZjjVZ1THMAIHEFBAAwQoAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY4GakCWZU8leeZz4LDe+ClQDAxXEFBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY4GakCeb/fDbWegkA8INwBQQAMEGAAAAmPAdo165dmj59uoLBoHw+n7Zs2RL1/IIFC+Tz+aK2oqKieK0XAJAgPAeopaVFubm5Wr16daf7FBUV6ejRo5Ft48aNl7RIAEDi8fwhhOLiYhUXF190H7/fr8zMzJgXBQBIfF3yHlBFRYXS09M1ZswYLV68WMePH+9039bWVoXD4agNAJD44h6goqIivfrqqyovL9dvfvMbVVZWqri4WOfOnetw/7KyMgUCgciWnZ0d7yUBALqhuP8c0Lx58yK/Hj9+vCZMmKCRI0eqoqJCU6dOvWD/0tJSLV++PPJ1OBwmQgDQC3T5x7BHjBihtLQ01dXVdfi83+9XSkpK1AYASHxdHqAvv/xSx48fV1ZWVlcfCgDQg3j+I7iTJ09GXc3U19dr3759Sk1NVWpqqp555hnNmTNHmZmZOnTokB577DGNGjVKhYWFcV04AKBn8xygPXv26I477oh8/e37N/Pnz9eaNWu0f/9+/eEPf9CJEycUDAY1bdo0/frXv5bf74/fqgEAPZ7nAE2ZMkXOuU6ff/fddy9pQbg0/g+TPc8kFzV2wUqA7sN387iY5t6490XPMz/ftNTzzAhVeZ5JBNwLDgBgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACbi/ldyo+f5xbUfxDS3UcE4rwToGv/xUFJMc2l92zzPjHisd97ZOhZcAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJrgZKXTTFYdjmnvjxgLPM+37PonpWMC3+uUM9zzzXydtj+lYk3c+7HlmtGpiOlZvxBUQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCm5EmmGv+d6PnmexH2mM61rFfn/U8kz53oOeZ9lOnPM8gcY39lwbPMzde8UVMxxq+0RfTHH4YroAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABPcjDTBnDv4meeZ++tnxHSsj2563fNM3l0lnmeGbPw3zzPcwPTy8/Xz/tvJwedv9jzzrxkvep6Z/OwyzzOSNOTdqpjm8MNwBQQAMEGAAAAmPAWorKxMt9xyi5KTk5Wenq6ZM2eqtrY2ap/Tp0+rpKREgwcP1lVXXaU5c+aoqakprosGAPR8ngJUWVmpkpISVVdXa8eOHWpra9O0adPU0tIS2WfZsmV6++23tWnTJlVWVurIkSOaPXt23BcOAOjZPL1ruH379qiv169fr/T0dNXU1Gjy5MkKhUJ65ZVXtGHDBv30pz+VJK1bt04/+tGPVF1drR//+MfxWzkAoEe7pPeAQqGQJCk1NVWSVFNTo7a2NhUUFET2GTt2rIYNG6aqqo4/TdLa2qpwOBy1AQASX8wBam9v19KlS3Xrrbdq3LhxkqTGxkYlJSVp0KBBUftmZGSosbGxw+9TVlamQCAQ2bKzs2NdEgCgB4k5QCUlJTpw4IBef937z4L8rdLSUoVCocjW0NBwSd8PANAzxPSDqEuWLNG2bdu0a9cuDR06NPJ4Zmamzpw5oxMnTkRdBTU1NSkzM7PD7+X3++X3+2NZBgCgB/N0BeSc05IlS7R582bt3LlTOTk5Uc9PnDhR/fv3V3l5eeSx2tpaHT58WPn5+fFZMQAgIXi6AiopKdGGDRu0detWJScnR97XCQQCGjBggAKBgO6//34tX75cqampSklJ0UMPPaT8/Hw+AQcAiOIpQGvWrJEkTZkyJerxdevWacGCBZKk3/72t+rTp4/mzJmj1tZWFRYW6ne/+11cFgsASBw+55yzXsTfCofDCgQCmqIZ6ufrb72cXqHv6BExzT23Y4PnmRv6J3meGbPxQc8zo/85to/zt+/7JKa5RNMvZ7jnmU8f6fh93os5OGuN55lRWxd5nrnuwY88zyB2Z12bKrRVoVBIKSkpne7HveAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggrthI2ax3EX7qXc3eZ65xe/zPPOn1tj+32rha4s9z6R+6v0/oYGNbZ5nvh7v/W8Obh51zvOMJK3/2T95nsn3ez/WrfvmeZ5Jm/8XzzPnvj7ueQax427YAIBujQABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwwc1IcVm1/+TvPM98vfwbzzMrrt/meUaSpg8MxzSXaJYdzfM88+Gamz3PDH6lyvMMuj9uRgoA6NYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABP9rBeA3qVP5V7PM+mV3o/zv8YUeR+S9MiTyZ5nfH2838/3n3/8iueZez78heeZlOoBnmckKav8K88zgz/lxqLwhisgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAENyNFQjpXWxfT3Kh747yQTqzQRM8zo+T9Rq6xOnfZjoTejCsgAIAJAgQAMOEpQGVlZbrllluUnJys9PR0zZw5U7W1tVH7TJkyRT6fL2pbtGhRXBcNAOj5PAWosrJSJSUlqq6u1o4dO9TW1qZp06appaUlar+FCxfq6NGjkW3VqlVxXTQAoOfz9CGE7du3R329fv16paenq6amRpMnT448PnDgQGVmZsZnhQCAhHRJ7wGFQiFJUmpqatTjr732mtLS0jRu3DiVlpbq1KlTnX6P1tZWhcPhqA0AkPhi/hh2e3u7li5dqltvvVXjxo2LPH733Xdr+PDhCgaD2r9/vx5//HHV1tbqrbfe6vD7lJWV6Zlnnol1GQCAHsrnnHOxDC5evFh//OMf9cEHH2jo0KGd7rdz505NnTpVdXV1Gjly5AXPt7a2qrW1NfJ1OBxWdna2pmiG+vn6x7I0AIChs65NFdqqUCiklJSUTveL6QpoyZIl2rZtm3bt2nXR+EhSXl6eJHUaIL/fL7/fH8syAAA9mKcAOef00EMPafPmzaqoqFBOTs73zuzbt0+SlJWVFdMCAQCJyVOASkpKtGHDBm3dulXJyclqbGyUJAUCAQ0YMECHDh3Shg0bdOedd2rw4MHav3+/li1bpsmTJ2vChAld8g8AAOiZPL0H5PP5Onx83bp1WrBggRoaGnTvvffqwIEDamlpUXZ2tmbNmqUnnnjion8O+LfC4bACgQDvAQFAD9Ul7wF9X6uys7NVWVnp5VsCAHop7gUHADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADDRz3oB3+WckySdVZvkjBcDAPDsrNok/fX38850uwA1NzdLkj7QO8YrAQBciubmZgUCgU6f97nvS9Rl1t7eriNHjig5OVk+ny/quXA4rOzsbDU0NCglJcVohfY4D+dxHs7jPJzHeTivO5wH55yam5sVDAbVp0/n7/R0uyugPn36aOjQoRfdJyUlpVe/wL7FeTiP83Ae5+E8zsN51ufhYlc+3+JDCAAAEwQIAGCiRwXI7/drxYoV8vv91ksxxXk4j/NwHufhPM7DeT3pPHS7DyEAAHqHHnUFBABIHAQIAGCCAAEATBAgAICJHhOg1atX69prr9UVV1yhvLw8ffTRR9ZLuuyefvpp+Xy+qG3s2LHWy+pyu3bt0vTp0xUMBuXz+bRly5ao551zeuqpp5SVlaUBAwaooKBABw8etFlsF/q+87BgwYILXh9FRUU2i+0iZWVluuWWW5ScnKz09HTNnDlTtbW1UfucPn1aJSUlGjx4sK666irNmTNHTU1NRivuGj/kPEyZMuWC18OiRYuMVtyxHhGgN954Q8uXL9eKFSv08ccfKzc3V4WFhTp27Jj10i67G264QUePHo1sH3zwgfWSulxLS4tyc3O1evXqDp9ftWqVXnrpJa1du1a7d+/WlVdeqcLCQp0+ffoyr7Rrfd95kKSioqKo18fGjRsv4wq7XmVlpUpKSlRdXa0dO3aora1N06ZNU0tLS2SfZcuW6e2339amTZtUWVmpI0eOaPbs2Yarjr8fch4kaeHChVGvh1WrVhmtuBOuB5g0aZIrKSmJfH3u3DkXDAZdWVmZ4aouvxUrVrjc3FzrZZiS5DZv3hz5ur293WVmZrrnn38+8tiJEyec3+93GzduNFjh5fHd8+Ccc/Pnz3czZswwWY+VY8eOOUmusrLSOXf+333//v3dpk2bIvt8+umnTpKrqqqyWmaX++55cM65n/zkJ+7hhx+2W9QP0O2vgM6cOaOamhoVFBREHuvTp48KCgpUVVVluDIbBw8eVDAY1IgRI3TPPffo8OHD1ksyVV9fr8bGxqjXRyAQUF5eXq98fVRUVCg9PV1jxozR4sWLdfz4cesldalQKCRJSk1NlSTV1NSora0t6vUwduxYDRs2LKFfD989D9967bXXlJaWpnHjxqm0tFSnTp2yWF6nut3NSL/r66+/1rlz55SRkRH1eEZGhv785z8brcpGXl6e1q9frzFjxujo0aN65plndPvtt+vAgQNKTk62Xp6JxsZGSerw9fHtc71FUVGRZs+erZycHB06dEi/+tWvVFxcrKqqKvXt29d6eXHX3t6upUuX6tZbb9W4ceMknX89JCUladCgQVH7JvLroaPzIEl33323hg8frmAwqP379+vxxx9XbW2t3nrrLcPVRuv2AcJfFRcXR349YcIE5eXlafjw4XrzzTd1//33G64M3cG8efMivx4/frwmTJigkSNHqqKiQlOnTjVcWdcoKSnRgQMHesX7oBfT2Xl44IEHIr8eP368srKyNHXqVB06dEgjR4683MvsULf/I7i0tDT17dv3gk+xNDU1KTMz02hV3cOgQYN03XXXqa6uznopZr59DfD6uNCIESOUlpaWkK+PJUuWaNu2bXr//fej/vqWzMxMnTlzRidOnIjaP1FfD52dh47k5eVJUrd6PXT7ACUlJWnixIkqLy+PPNbe3q7y8nLl5+cbrszeyZMndejQIWVlZVkvxUxOTo4yMzOjXh/hcFi7d+/u9a+PL7/8UsePH0+o14dzTkuWLNHmzZu1c+dO5eTkRD0/ceJE9e/fP+r1UFtbq8OHDyfU6+H7zkNH9u3bJ0nd6/Vg/SmIH+L11193fr/frV+/3n3yySfugQcecIMGDXKNjY3WS7usHnnkEVdRUeHq6+vdn/70J1dQUODS0tLcsWPHrJfWpZqbm93evXvd3r17nST3wgsvuL1797ovvvjCOefcc8895wYNGuS2bt3q9u/f72bMmOFycnLcN998Y7zy+LrYeWhubnaPPvqoq6qqcvX19e69995zN910kxs9erQ7ffq09dLjZvHixS4QCLiKigp39OjRyHbq1KnIPosWLXLDhg1zO3fudHv27HH5+fkuPz/fcNXx933noa6uzq1cudLt2bPH1dfXu61bt7oRI0a4yZMnG688Wo8IkHPOvfzyy27YsGEuKSnJTZo0yVVXV1sv6bKbO3euy8rKcklJSe6aa65xc+fOdXV1ddbL6nLvv/++k3TBNn/+fOfc+Y9iP/nkky4jI8P5/X43depUV1tba7voLnCx83Dq1Ck3bdo0N2TIENe/f383fPhwt3DhwoT7n7SO/vkluXXr1kX2+eabb9yDDz7orr76ajdw4EA3a9Ysd/ToUbtFd4HvOw+HDx92kydPdqmpqc7v97tRo0a5X/7yly4UCtku/Dv46xgAACa6/XtAAIDERIAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY+H/n9Pp7GXoOuQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for data,target in test_loader:\n",
    "    plt.imshow(data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.0001)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "# Function to save the model\n",
    "def saveModel():\n",
    "    path = \"./myFirstModel.pth\"\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "# Function to test the model with the test dataset and print the accuracy for the test images\n",
    "def testAccuracy():\n",
    "    \n",
    "    model.eval()\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            # run the model on the test set to predict labels\n",
    "            outputs = model(images)\n",
    "            # the label with the highest energy will be our prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "    \n",
    "    # compute the accuracy over all test images\n",
    "    print(\"{}/{}\".format(accuracy,total))\n",
    "    accuracy = float(100 * accuracy / total)\n",
    "    return(accuracy)\n",
    "\n",
    "\n",
    "# Training function. We simply have to loop over our data iterator and feed the inputs to the network and optimize.\n",
    "def train(num_epochs):\n",
    "    \n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    # Define your execution device\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"The model will be running on\", device, \"device\")\n",
    "    # Convert model parameters and buffers to CPU or Cuda\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_loader, 0):\n",
    "            \n",
    "            # get the inputs\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad(set_to_none=False)\n",
    "            # predict classes using images from the training set\n",
    "            outputs = model(images)\n",
    "            # compute the loss based on model output and real labels\n",
    "            loss = loss_function(outputs, labels)\n",
    "            # backpropagate the loss\n",
    "            loss.backward()\n",
    "            # adjust parameters based on the calculated gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            # Let's print statistics for every 1,000 images\n",
    "            running_loss += loss.item()     # extract the loss value\n",
    "            if i % 1000 == 999:    \n",
    "                # print every 1000 (twice per epoch) \n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 1000))\n",
    "                # zero the loss\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Compute and print the average accuracy fo this epoch when tested over all 10000 test images\n",
    "        accuracy = testAccuracy()\n",
    "        print('For epoch', epoch+1,'the test accuracy over the whole test set is %.2f %%' % (accuracy))\n",
    "        \n",
    "        # we want to save the model if the accuracy is the best\n",
    "        if accuracy > best_accuracy:\n",
    "            saveModel()\n",
    "            best_accuracy = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model will be running on cuda:0 device\n",
      "[1,  1000] loss: 0.759\n",
      "9743.0/10000.0\n",
      "For epoch 1 the test accuracy over the whole test set is 97.43 %\n",
      "[2,  1000] loss: 0.073\n",
      "9871.0/10000.0\n",
      "For epoch 2 the test accuracy over the whole test set is 98.71 %\n",
      "[3,  1000] loss: 0.045\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train(\u001b[39m20\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[9], line 60\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(num_epochs)\u001b[0m\n\u001b[0;32m     58\u001b[0m loss \u001b[39m=\u001b[39m loss_function(outputs, labels)\n\u001b[0;32m     59\u001b[0m \u001b[39m# backpropagate the loss\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     61\u001b[0m \u001b[39m# adjust parameters based on the calculated gradients\u001b[39;00m\n\u001b[0;32m     62\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\get2b\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\get2b\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4a96baaf79f14888d285bcba7f550195ef41d580783ed1a8999b5f8e1380f57b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
