{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "import warnings\n",
    "from torch.nn.modules.utils import _pair\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv(nn.Module):\n",
    "    \n",
    "    def __init__(self, c, s):\n",
    "    \n",
    "        super().__init__()\n",
    "        \n",
    "        if s==1:\n",
    "            self.seq = nn.Sequential(nn.Conv2d(in_channels=c,out_channels=c,stride=s,padding=1,kernel_size=3),nn.BatchNorm2d(num_features=c),nn.SiLU())\n",
    "        if s==2:\n",
    "            self.seq = nn.Sequential(nn.Conv2d(in_channels=c,out_channels=2*c,stride=s,padding=1,kernel_size=3),nn.BatchNorm2d(num_features=2*c),nn.SiLU())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.seq(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPconv(nn.Module):\n",
    "    \n",
    "    def __init__(self,c):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2,stride=1)\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels=c,out_channels=2*c,stride=2,kernel_size=1),nn.BatchNorm2d(num_features=2*c),nn.SiLU())\n",
    "        self.conv2 = conv(c,2)\n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(in_channels=c,out_channels=c,stride=1,kernel_size=1),nn.BatchNorm2d(num_features=c),nn.SiLU())\n",
    "        self.conv4 = nn.Sequential(nn.Conv2d(in_channels=4*c,out_channels=2*c,stride=1,kernel_size=1),nn.BatchNorm2d(num_features=2*c),nn.SiLU())\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        xa = self.maxpool(x)\n",
    "        xa = self.conv1(xa)\n",
    "        \n",
    "        xb = self.conv3(x)\n",
    "        xb = self.conv2(xb)\n",
    "        \n",
    "        x = torch.concat((xa,xb),dim=1)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class REPconv(nn.Module):\n",
    "    \n",
    "    def __init__(self,c):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels=c,out_channels=c,stride=1,kernel_size=1),nn.BatchNorm2d(num_features=c),nn.SiLU())\n",
    "        self.conv2 = conv(c,1)\n",
    "        self.bn = nn.BatchNorm2d(c)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv2(x)\n",
    "        x3 = self.bn(x)\n",
    "        \n",
    "        if self.training:\n",
    "            x = torch.add(x1,x2)\n",
    "            x = torch.add(x,x3)\n",
    "            return x\n",
    "        else:\n",
    "            return x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELAN1(nn.Module):\n",
    "    \n",
    "    def __init__(self,c):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.convELEN1a = nn.Sequential(nn.Conv2d(in_channels=c,out_channels=c,stride=1,kernel_size=1),nn.BatchNorm2d(num_features=c),nn.SiLU())\n",
    "        self.convELEN1b = nn.Sequential(nn.Conv2d(in_channels=c,out_channels=c,stride=1,kernel_size=1),nn.BatchNorm2d(num_features=c),nn.SiLU())\n",
    "        self.convELEN1c = conv(c,1)\n",
    "        self.convELEN1d = conv(c,1)\n",
    "        self.convELEN1e = conv(c,1)\n",
    "        self.convELEN1f = conv(c,1)\n",
    "        self.convELEN1g = nn.Sequential(nn.Conv2d(in_channels=3*c,out_channels=c,stride=1,kernel_size=1),nn.BatchNorm2d(num_features=c),nn.SiLU())\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x1 = self.convELEN1a(x)\n",
    "        x2 = self.convELEN1b(x)\n",
    "        x3 = self.convELEN1c(x1)\n",
    "        x3 = self.convELEN1d(x3)\n",
    "        x4 = self.convELEN1e(x3)\n",
    "        x4 = self.convELEN1f(x4)\n",
    "        \n",
    "        x = torch.cat((x2,x3,x4),dim=1)\n",
    "        \n",
    "        x = self.convELEN1g(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELAN2(nn.Module):\n",
    "    \n",
    "    def __init__(self,c):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.convELEN1a = nn.Sequential(nn.Conv2d(in_channels=c,out_channels=c,stride=1,kernel_size=1),nn.BatchNorm2d(num_features=c),nn.SiLU())\n",
    "        self.convELEN1b = nn.Sequential(nn.Conv2d(in_channels=c,out_channels=c,stride=1,kernel_size=1),nn.BatchNorm2d(num_features=c),nn.SiLU())\n",
    "        self.convELEN1c = conv(c,1)\n",
    "        self.convELEN1d = conv(c,1)\n",
    "        self.convELEN1e = conv(c,1)\n",
    "        self.convELEN1f = conv(c,1)\n",
    "        self.convELEN1g = nn.Sequential(nn.Conv2d(in_channels=5*c,out_channels=c,stride=1,kernel_size=1),nn.BatchNorm2d(num_features=c),nn.SiLU())\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x1 = self.convELEN1a(x)\n",
    "        x2 = self.convELEN1b(x)\n",
    "        x3 = self.convELEN1c(x1)\n",
    "        x4 = self.convELEN1d(x3)\n",
    "        x5 = self.convELEN1e(x4)\n",
    "        x6 = self.convELEN1f(x5)\n",
    "        \n",
    "        x = torch.concat((x2,x3,x4,x5,x6),dim=1)\n",
    "        \n",
    "        x = self.convELEN1g(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPPCSPC(nn.Module):\n",
    "    \n",
    "    def __init__(self,c):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1a = nn.Sequential(nn.Conv2d(in_channels=c,out_channels=c,stride=1,kernel_size=1),nn.BatchNorm2d(num_features=c),nn.SiLU())\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(in_channels=c,out_channels=c,stride=1,kernel_size=1),nn.BatchNorm2d(num_features=c),nn.SiLU())\n",
    "        self.conv1b = conv(c,1)\n",
    "        self.conv1c = nn.Sequential(nn.Conv2d(in_channels=c,out_channels=c,stride=1,kernel_size=1),nn.BatchNorm2d(num_features=c),nn.SiLU())\n",
    "        self.maxpool1a = nn.MaxPool2d(kernel_size=5,padding=2)\n",
    "        self.maxpool1b = nn.MaxPool2d(kernel_size=9,padding=4)\n",
    "        self.maxpool1c = nn.MaxPool2d(kernel_size=13,padding=6)\n",
    "        self.conv1d = nn.Sequential(nn.Conv2d(in_channels=4*c,out_channels=c,stride=1,kernel_size=1),nn.BatchNorm2d(num_features=c),nn.SiLU())\n",
    "        self.conv1e = conv(c,1)\n",
    "        self.conv1f = nn.Sequential(nn.Conv2d(in_channels=2*c,out_channels=c,stride=1,kernel_size=1),nn.BatchNorm2d(num_features=c),nn.SiLU())\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x1a = self.conv1a(x)\n",
    "        x2 = self.conv2(x)\n",
    "        \n",
    "        x1b = self.conv1b(x1a)\n",
    "        x1c = self.conv1c(x1b)\n",
    "        x1ma = self.maxpool1a(x1c)\n",
    "        sfa = (x1c.shape[2]/x1ma.shape[2])\n",
    "        x1ma = nn.UpsamplingBilinear2d(scale_factor=sfa)(x1ma)\n",
    "        x1mb = self.maxpool1b(x1c)\n",
    "        sfb = (x1c.shape[2]/x1mb.shape[2])\n",
    "        x1mb = nn.UpsamplingBilinear2d(scale_factor=sfb)(x1mb)\n",
    "        x1mc = self.maxpool1c(x1c)\n",
    "        sfc = (x1c.shape[2]/x1mc.shape[2])\n",
    "        x1mc = nn.UpsamplingBilinear2d(scale_factor=sfc)(x1mc)\n",
    "        x1c = torch.cat((x1c,x1ma,x1mb,x1mc),dim=1)\n",
    "        \n",
    "        x1d = self.conv1d(x1c)\n",
    "        x1e = self.conv1e(x1d)\n",
    "        x = torch.cat((x1e,x2),dim=1)\n",
    "        \n",
    "        x = self.conv1f(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Backbone(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels=3,out_channels=32,stride=1,kernel_size=3,padding=1),nn.BatchNorm2d(num_features=32),nn.SiLU())\n",
    "        self.conv2 = conv(32,2)         #This will give output of 64 channels\n",
    "        self.conv3 = conv(64,1)\n",
    "        self.conv4 = conv(64,2)         #This will give output of 128 channels\n",
    "        self.ELAN1a = ELAN1(128)\n",
    "        self.MPconv1 = MPconv(128)      #This will give output of 256 channels\n",
    "        self.ELAN1b = ELAN1(256)\n",
    "        self.MPconv2 = MPconv(256)      #This will give output of 512 channels\n",
    "        self.ELAN1c = ELAN1(512)\n",
    "        self.MPconv3 = MPconv(512)      #This will give output of 1024 channels\n",
    "        self.ELAN1d = ELAN1(1024)\n",
    "        self.SPPCSPC = SPPCSPC(1024)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.ELAN1a(x)\n",
    "        x = self.MPconv1(x)\n",
    "        x1 = self.ELAN1b(x)\n",
    "        x2 = self.MPconv2(x1)\n",
    "        x2 = self.ELAN1c(x2)\n",
    "        x3 = self.MPconv3(x2)\n",
    "        x3 = self.ELAN1d(x3)\n",
    "        x3 = self.SPPCSPC(x3)\n",
    "        \n",
    "        return (x1,x2,x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class head(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.backbone = Backbone()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels=1024,out_channels=512,stride=1,kernel_size=1),nn.BatchNorm2d(num_features=512),nn.SiLU())\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(in_channels=512,out_channels=512,stride=1,kernel_size=1),nn.BatchNorm2d(num_features=512),nn.SiLU())\n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(in_channels=256,out_channels=256,stride=1,kernel_size=1),nn.BatchNorm2d(num_features=256),nn.SiLU())\n",
    "        self.upsample1 = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "        self.convCat1 = nn.Sequential(nn.Conv2d(in_channels=1024,out_channels=512,stride=1,kernel_size=1),nn.BatchNorm2d(num_features=512),nn.SiLU())\n",
    "        self.ELAN2a = ELAN2(512)\n",
    "        self.conv4 = nn.Sequential(nn.Conv2d(in_channels=512,out_channels=256,stride=1,kernel_size=1),nn.BatchNorm2d(num_features=256),nn.SiLU())\n",
    "        self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "        self.convCat2 = nn.Sequential(nn.Conv2d(in_channels=768,out_channels=256,stride=1,kernel_size=1),nn.BatchNorm2d(num_features=256),nn.SiLU())\n",
    "        \n",
    "        self.ELAN2b = ELAN2(256)\n",
    "        self.MPconv1 = MPconv(256) # The output for this is 512 channels\n",
    "        self.ELAN2c = ELAN2(512)\n",
    "        self.MPconv2 = MPconv(512) # The output for this is 1024 channels\n",
    "        self.ELAN2d = ELAN2(1024)\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        y = self.backbone(x)\n",
    "        x1 = self.conv1(y[2])\n",
    "        x1 = self.upsample1(x1)\n",
    "        x1 = torch.cat((x1,y[1]),dim=1)\n",
    "        x1 = self.convCat1(x1)\n",
    "        x1 = self.ELAN2a(x1)\n",
    "        \n",
    "        x2 = self.conv2(x1)\n",
    "        x2 = self.upsample2(x2)\n",
    "        x2 = torch.cat((x2,y[0]),dim=1)\n",
    "        x2 = self.convCat2(x2)\n",
    "        x2 = self.ELAN2b(x2)\n",
    "        \n",
    "        x3 = self.MPconv1(x2)\n",
    "        x3 = torch.cat((x1,x3),dim=1)\n",
    "        x3 = nn.Conv2d(in_channels=1024,out_channels=512,kernel_size=1)(x3)\n",
    "        x3 = self.ELAN2c(x3)\n",
    "        \n",
    "        x4 = self.MPconv2(x3)\n",
    "        x4 = torch.cat((x4,y[2]),dim=1)\n",
    "        x4 = nn.Conv2d(in_channels=2048,out_channels=1024,kernel_size=1)(x4)\n",
    "        x4 = self.ELAN2d(x4)\n",
    "        \n",
    "        \n",
    "        return (x2,x3,x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class detection_head(nn.Module):\n",
    "    \n",
    "    def __init__(self,no_of_classes,no_of_anchors):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.head = head()\n",
    "        \n",
    "        self.BBRegConv_20x20 = nn.Conv2d(in_channels=1024,out_channels=4*no_of_anchors,kernel_size=1,stride=1)\n",
    "        self.BBRegConv_40x40 = nn.Conv2d(in_channels=512,out_channels=4*no_of_anchors,kernel_size=1,stride=1)\n",
    "        self.BBRegConv_80x80 = nn.Conv2d(in_channels=256,out_channels=4*no_of_anchors,kernel_size=1,stride=1)\n",
    "        \n",
    "        self.objectness_20x20 = nn.Conv2d(in_channels=1024,out_channels=1*no_of_anchors,kernel_size=1,stride=1)\n",
    "        self.objectness_40x40 = nn.Conv2d(in_channels=512,out_channels=1*no_of_anchors,kernel_size=1,stride=1)\n",
    "        self.objectness_80x80 = nn.Conv2d(in_channels=256,out_channels=1*no_of_anchors,kernel_size=1,stride=1)\n",
    "        \n",
    "        self.classes_20x20 = nn.Conv2d(in_channels=1024,out_channels=no_of_classes*no_of_anchors,kernel_size=1,stride=1)\n",
    "        self.classes_40x40 = nn.Conv2d(in_channels=512,out_channels=no_of_classes*no_of_anchors,kernel_size=1,stride=1)\n",
    "        self.classes_80x80 = nn.Conv2d(in_channels=256,out_channels=no_of_classes*no_of_anchors,kernel_size=1,stride=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = self.head(x)\n",
    "        # x is the output of the head class which has the follow layout\n",
    "        # (x2,x3,x4) has 256, 512, 1024 filters respectively\n",
    "        # which means that the feature map sizes are 80x80,40x40, and 20x20 for a 640x640 image\n",
    "        \n",
    "        reg1 = self.BBRegConv_20x20(x[2])\n",
    "        reg2 = self.BBRegConv_40x40(x[1])\n",
    "        reg3 = self.BBRegConv_80x80(x[0])\n",
    "        \n",
    "        obj1 = self.objectness_20x20(x[2])\n",
    "        obj2 = self.objectness_40x40(x[1])\n",
    "        obj3 = self.objectness_80x80(x[0])\n",
    "        \n",
    "        cls1 = self.classes_20x20(x[2])\n",
    "        cls2 = self.classes_40x40(x[1])\n",
    "        cls3 = self.classes_80x80(x[0])\n",
    "        \n",
    "        return((reg1,obj1,cls1),(reg2,obj2,cls2),(reg3,obj3,cls3),x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 60, 20, 20])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = detection_head(20,3)\n",
    "a = torch.rand((4,3,640,640))\n",
    "model(a)[0][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anchors(feat_map, img_size):\n",
    "    \n",
    "    center_points = []\n",
    "    for feat_maps in feat_map:\n",
    "        cp=[]\n",
    "        for i in range(feat_maps.shape[2]):\n",
    "            for j in range(feat_maps.shape[2]):\n",
    "                cp.append((i,j))\n",
    "        center_points.append(cp)\n",
    "    \n",
    "    useful_anchors = []\n",
    "    for feat_maps in feat_map:\n",
    "        anchor_types = np.asarray(((128,128),(128,256),(256,128)))/(img_size/feat_maps.shape[2])\n",
    "        useful_anchors1 = []\n",
    "        useful_anchors2 = []\n",
    "        useful_anchors3 = []\n",
    "        x = y = feat_maps.shape[2]\n",
    "        for k in anchor_types:\n",
    "            flag = True\n",
    "            for i in range(x):\n",
    "                for j in range(y):\n",
    "                    if((i - (k[0]/2)) < 0 or (j - (k[1]/2)) < 0 or (i + (k[0]/2)) > x or (j + (k[1]/2)) > y):\n",
    "                        flag = False\n",
    "                    else:\n",
    "                        if(k[0] == k[1]):\n",
    "                            useful_anchors1.append((i,j,k[0]/2,k[1]/2))\n",
    "                        elif (k[0]<k[1]):\n",
    "                            useful_anchors2.append((i,j,k[0]/2,k[1]/2))\n",
    "                        else:\n",
    "                            useful_anchors3.append((i,j,k[0]/2,k[1]/2))\n",
    "        useful_anchors.append((useful_anchors1,useful_anchors2,useful_anchors3))\n",
    "    return useful_anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IoU(nn.Module):\n",
    "    \n",
    "    def __init__(self,img_size,no_of_classes,ground_truth,feat_map) -> None:\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.img_size = img_size\n",
    "        self.no_of_classes = no_of_classes\n",
    "        self.ground_truth = ground_truth\n",
    "        self.feat_maps = feat_map\n",
    "        \n",
    "    def forward(self,x,feat_maps):\n",
    "        \n",
    "        obj = []\n",
    "        reg = []\n",
    "        cla = []    # cla is for class\n",
    "        # range is from 0 to 3 since we have only 3 anchor boxes\n",
    "        for i in range(0,3):\n",
    "            obj.append(x[ : , ( 0 + ( 1 * i ) ) : ( 1 + ( 1 * i ) ) , : , : ])\n",
    "            reg.append(x[ : , ( 0 + ( 4 * i ) ) : ( 4 + ( 4 * i ) ) , : , : ])\n",
    "            cla.append(x[:,(0+(self.no_of_classes*i)):(self.no_of_classes+(self.no_of_classes*i)),:,:])\n",
    "        # The three sizes of the anchors are ((128,128),(128,256),(256,128))\n",
    "        anchor_boxes = anchors(self.feat_maps, self.img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class loss(nn.Module):\n",
    "    \n",
    "    def __init__(self,no_of_classes,img_size, ground_truth) -> None:\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.detection_head = detection_head(no_of_classes=no_of_classes,no_of_anchors=3)\n",
    "        self.IoU = IoU(img_size,no_of_classes,ground_truth)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = self.detection_head(x)\n",
    "        # x[0] = it has the 20x20 feature maps info\n",
    "        # x[1] = it has the 40x40 feature maps info\n",
    "        # x[2] = it has the 80x80 feature maps info\n",
    "        iou1 = self.IoU(x[0],x[3])\n",
    "        # The three sizes of the anchors are ((128,128),(128,256),(256,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(anchors(torch.rand((4,1024,20,20)),640)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 20, 20])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ground_truth = torch.Tensor([[2,2,5,6],[3,3,7,8]])\n",
    "x = torch.rand((4,60,20,20))\n",
    "reg = []\n",
    "for i in range(0,3):\n",
    "    reg.append(x[ : , ( 0 + ( 4 * i ) ) : ( 4 + ( 4 * i ) ) , : , : ])\n",
    "reg[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "731"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(anchors(feat_maps=torch.rand((4,1024,20,20)),img_size=640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 4.],\n",
       "       [4., 8.],\n",
       "       [8., 4.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_size = 640\n",
    "feat_maps = torch.rand((4,3,20,20))\n",
    "anchor_types = np.asarray([[128,128],[128,256],[256,128]])/(img_size/feat_maps.shape[2])\n",
    "anchor_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anchor_type(size = (4,8,16),ratio = (2,1,0.5)):\n",
    "    anchor_types = []\n",
    "    for i in size:\n",
    "        for j in ratio:\n",
    "            anchor_types.append((int(i),int(i*j)))\n",
    "    return anchor_types\n",
    "def anchorGen(feat_maps):\n",
    "    center_points = []\n",
    "    for feat_map in feat_maps:\n",
    "        cp=[]\n",
    "        for i in range(feat_map.shape[2]):\n",
    "            for j in range(feat_map.shape[2]):\n",
    "                cp.append((i,j))\n",
    "        center_points.append(cp)\n",
    "    return center_points\n",
    "def usable_anchors(feat_maps,size=(4,8,16),ratio=(2,1,0.5)):\n",
    "    anchor_types = anchor_type()\n",
    "    useful_anchors = []\n",
    "    x = y = feat_maps.shape[2]\n",
    "    for i in range(x):\n",
    "        for j in range(y):\n",
    "            flag = True\n",
    "            for k in anchor_types:\n",
    "                if((i - (k[0]/2)) < 0 or (j - (k[1]/2)) < 0 or (i + (k[0]/2)) > x or (j + (k[1]/2)) > y):\n",
    "                    flag = False\n",
    "                else:\n",
    "                    useful_anchors.append((i,j,k[0]/2,k[1]/2))\n",
    "    return useful_anchors\n",
    "def convert(anchors_to_be_converted):\n",
    "    converted_anchors = []\n",
    "    for i in anchors_to_be_converted:\n",
    "        xmax = (i[0] + i[2]/2)\n",
    "        ymax = (i[1] + i[3]/2)\n",
    "        xmin = (i[0] - i[2]/2)\n",
    "        ymin = (i[1] - i[3]/2)\n",
    "        converted_anchors.append((xmax,ymax,xmin,ymin))\n",
    "    return converted_anchors\n",
    "def iou_threshold(feat_maps, ground_truth, threshold = 0.49):\n",
    "    anchors = usable_anchors(feat_maps)\n",
    "    anchors = convert(anchors)\n",
    "    ground_truth = convert(ground_truth)\n",
    "    f_anchors=[]\n",
    "    finalized_anchors = []\n",
    "    scores=[]\n",
    "    for i in anchors:\n",
    "        for j in ground_truth:\n",
    "            area_intersection = (min(i[0],j[0])-max(i[2],j[2])) * (min(i[1],j[1])-max(i[3],j[3]))\n",
    "            area_box1 = (i[0]-i[2])*(i[1]-i[3])\n",
    "            area_box2 = (j[0]-j[2])*(j[1]-j[3])\n",
    "            iou = area_intersection/(area_box1+area_box2-area_intersection+1e-6)\n",
    "            if iou>threshold and iou<1 and area_intersection>0 and (min(i[0],j[0])-max(i[2],j[2]))>0:\n",
    "                f_anchors.append(i)\n",
    "                scores.append(iou)\n",
    "    return f_anchors,scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted label has 4 parts where the parts are dx,dy,dw,dh\n",
    "# dx = adjustment to center\n",
    "# dy = adjustment to center\n",
    "# dw = adjustment to width\n",
    "# dh = adjustment to height\n",
    "ground_truth = torch.Tensor([[2,2,5,6],[3,3,7,8]])\n",
    "predicted = torch.Tensor([[2,2,4.5,6],[2,4,5,4],[3,3,6.5,8],[3,5,6,9]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
